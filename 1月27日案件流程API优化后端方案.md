# 案件流程API优化后端方案

## 一、现状分析

### 1.1 当前接口调用流程

当前前端在加载案件流程数据时，需要进行以下接口调用：

```
1. 获取所有任务数据
   GET /api/v1/case-tasks?caseId={caseId}&page=1&size=100

2. 对每个任务获取最新提交记录（串行）
   GET /api/v1/case-task-submissions/latest?caseTaskId={taskId}

3. 对每个提交记录获取文件列表（串行）
   GET /api/v1/case-task-submissions/{submissionId}/files

4. 对每个图片文件获取预览（串行）
   GET /api/v1/file/preview/{fileId}
```

### 1.2 性能瓶颈

- **串行调用**：所有接口都是串行调用，没有利用并发
- **请求次数多**：假设有20个任务，每个任务有5个提交，每个提交有3个文件，则需要：
  - 1次获取任务列表
  - 20次获取提交记录
  - 100次获取文件列表
  - 300次获取图片预览（已通过前端懒加载优化）
  - **总计：421次请求**

- **响应时间长**：每次请求平均耗时100-200ms，总耗时可达40-80秒

## 二、优化方案

### 方案A：批量获取接口（推荐⭐⭐⭐⭐⭐）

#### 2.1 批量获取任务提交记录

**接口设计：**

```http
POST /api/v1/case-task-submissions/latest/batch
Content-Type: application/json
Authorization: Bearer {token}

{
  "caseTaskIds": [1, 2, 3, 4, 5]
}
```

**响应示例：**

```json
{
  "code": 200,
  "message": "success",
  "data": {
    "1": [
      {
        "id": 101,
        "caseTaskId": 1,
        "submissionTitle": "提交标题",
        "submissionContent": "提交内容",
        "submissionType": "NORMAL",
        "status": "APPROVED",
        "submissionNumber": 1,
        "creatorName": "张三",
        "createTime": "2024-01-27T10:00:00",
        "updateTime": "2024-01-27T10:00:00"
      }
    ],
    "2": [],
    "3": [
      {
        "id": 102,
        "caseTaskId": 3,
        "submissionTitle": "提交标题2",
        "submissionContent": "提交内容2",
        "submissionType": "NORMAL",
        "status": "PENDING",
        "submissionNumber": 1,
        "creatorName": "李四",
        "createTime": "2024-01-27T11:00:00",
        "updateTime": "2024-01-27T11:00:00"
      }
    ]
  }
}
```

**后端实现要点：**

```java
@PostMapping("/latest/batch")
public ResponseEntity<Map<Long, List<CaseTaskSubmission>>> getLatestSubmissionsBatch(
    @RequestBody BatchRequest request,
    @RequestHeader("Authorization") String token
) {
    // 1. 验证token和权限
    User user = authService.validateToken(token);

    // 2. 批量查询提交记录（使用IN语句）
    List<Long> caseTaskIds = request.getCaseTaskIds();
    List<CaseTaskSubmission> submissions = submissionRepository
        .findLatestByCaseTaskIds(caseTaskIds);

    // 3. 按caseTaskId分组
    Map<Long, List<CaseTaskSubmission>> result = submissions.stream()
        .collect(Collectors.groupingBy(CaseTaskSubmission::getCaseTaskId));

    return ResponseEntity.ok(result);
}
```

#### 2.2 批量获取提交文件

**接口设计：**

```http
POST /api/v1/case-task-submissions/files/batch
Content-Type: application/json
Authorization: Bearer {token}

{
  "submissionIds": [101, 102, 103, 104, 105]
}
```

**响应示例：**

```json
{
  "code": 200,
  "message": "success",
  "data": {
    "101": [
      {
        "id": 201,
        "submissionId": 101,
        "originalFileName": "document.pdf",
        "filePath": "/files/2024/01/27/document.pdf",
        "fileSize": 1024000,
        "mimeType": "application/pdf",
        "uploadTime": "2024-01-27T10:00:00",
        "uploadUserName": "张三",
        "sortOrder": 1
      }
    ],
    "102": [
      {
        "id": 202,
        "submissionId": 102,
        "originalFileName": "image.jpg",
        "filePath": "/files/2024/01/27/image.jpg",
        "fileSize": 512000,
        "mimeType": "image/jpeg",
        "uploadTime": "2024-01-27T11:00:00",
        "uploadUserName": "李四",
        "sortOrder": 1
      },
      {
        "id": 203,
        "submissionId": 102,
        "originalFileName": "image2.png",
        "filePath": "/files/2024/01/27/image2.png",
        "fileSize": 256000,
        "mimeType": "image/png",
        "uploadTime": "2024-01-27T11:00:00",
        "uploadUserName": "李四",
        "sortOrder": 2
      }
    ]
  }
}
```

**后端实现要点：**

```java
@PostMapping("/files/batch")
public ResponseEntity<Map<Long, List<SubmissionFile>>> getSubmissionFilesBatch(
    @RequestBody BatchRequest request,
    @RequestHeader("Authorization") String token
) {
    // 1. 验证token和权限
    User user = authService.validateToken(token);

    // 2. 批量查询文件（使用IN语句）
    List<Long> submissionIds = request.getSubmissionIds();
    List<SubmissionFile> files = fileRepository
        .findBySubmissionIds(submissionIds);

    // 3. 按submissionId分组并排序
    Map<Long, List<SubmissionFile>> result = files.stream()
        .sorted(Comparator.comparing(SubmissionFile::getSortOrder))
        .collect(Collectors.groupingBy(SubmissionFile::getSubmissionId));

    return ResponseEntity.ok(result);
}
```

### 方案B：聚合接口（推荐⭐⭐⭐⭐⭐）

#### 2.3 一次性获取案件所有相关数据

**接口设计：**

```http
GET /api/v1/cases/{caseId}/process-data
Authorization: Bearer {token}
```

**响应示例：**

```json
{
  "code": 200,
  "message": "success",
  "data": {
    "tasks": [
      {
        "id": 1,
        "caseId": 16,
        "taskName": "提交破产申请材料",
        "taskCode": "TASK_001_1",
        "status": "COMPLETED",
        "stage": 1,
        "moduleId": "1-1",
        "submissions": [
          {
            "id": 101,
            "caseTaskId": 1,
            "submissionTitle": "提交标题",
            "submissionContent": "提交内容",
            "submissionType": "NORMAL",
            "status": "APPROVED",
            "submissionNumber": 1,
            "creatorName": "张三",
            "createTime": "2024-01-27T10:00:00",
            "updateTime": "2024-01-27T10:00:00",
            "files": [
              {
                "id": 201,
                "submissionId": 101,
                "originalFileName": "document.pdf",
                "filePath": "/files/2024/01/27/document.pdf",
                "fileSize": 1024000,
                "mimeType": "application/pdf",
                "uploadTime": "2024-01-27T10:00:00",
                "uploadUserName": "张三",
                "sortOrder": 1,
                "previewUrl": "/api/v1/file/preview/201"
              }
            ]
          }
        ]
      },
      {
        "id": 2,
        "caseId": 16,
        "taskName": "法院立案形式审查",
        "taskCode": "TASK_001_2",
        "status": "IN_PROGRESS",
        "stage": 1,
        "moduleId": "1-2",
        "submissions": []
      }
    ]
  }
}
```

**后端实现要点：**

```java
@GetMapping("/cases/{caseId}/process-data")
public ResponseEntity<ProcessDataResponse> getCaseProcessData(
    @PathVariable Long caseId,
    @RequestHeader("Authorization") String token
) {
    // 1. 验证token和权限
    User user = authService.validateToken(token);

    // 2. 批量查询案件的所有任务
    List<CaseTask> tasks = taskRepository.findByCaseId(caseId);

    // 3. 批量查询所有任务的提交记录
    List<Long> taskIds = tasks.stream()
        .map(CaseTask::getId)
        .collect(Collectors.toList());
    List<CaseTaskSubmission> submissions = submissionRepository
        .findLatestByCaseTaskIds(taskIds);

    // 4. 批量查询所有提交的文件
    List<Long> submissionIds = submissions.stream()
        .map(CaseTaskSubmission::getId)
        .collect(Collectors.toList());
    List<SubmissionFile> files = fileRepository
        .findBySubmissionIds(submissionIds);

    // 5. 构建响应数据（使用Map快速查找）
    Map<Long, List<CaseTaskSubmission>> submissionMap = submissions.stream()
        .collect(Collectors.groupingBy(CaseTaskSubmission::getCaseTaskId));

    Map<Long, List<SubmissionFile>> fileMap = files.stream()
        .sorted(Comparator.comparing(SubmissionFile::getSortOrder))
        .collect(Collectors.groupingBy(SubmissionFile::getSubmissionId));

    // 6. 组装数据
    List<TaskData> taskDataList = tasks.stream()
        .map(task -> {
            List<CaseTaskSubmission> taskSubmissions =
                submissionMap.getOrDefault(task.getId(), Collections.emptyList());

            List<SubmissionData> submissionDataList = taskSubmissions.stream()
                .map(submission -> {
                    List<SubmissionFile> submissionFiles =
                        fileMap.getOrDefault(submission.getId(), Collections.emptyList());

                    List<FileData> fileDataList = submissionFiles.stream()
                        .map(file -> FileData.builder()
                            .id(file.getId())
                            .submissionId(file.getSubmissionId())
                            .originalFileName(file.getOriginalFileName())
                            .filePath(file.getFilePath())
                            .fileSize(file.getFileSize())
                            .mimeType(file.getMimeType())
                            .uploadTime(file.getUploadTime())
                            .uploadUserName(file.getUploadUserName())
                            .sortOrder(file.getSortOrder())
                            .previewUrl("/api/v1/file/preview/" + file.getId())
                            .build())
                        .collect(Collectors.toList());

                    return SubmissionData.builder()
                        .id(submission.getId())
                        .caseTaskId(submission.getCaseTaskId())
                        .submissionTitle(submission.getSubmissionTitle())
                        .submissionContent(submission.getSubmissionContent())
                        .submissionType(submission.getSubmissionType())
                        .status(submission.getStatus())
                        .submissionNumber(submission.getSubmissionNumber())
                        .creatorName(submission.getCreatorName())
                        .createTime(submission.getCreateTime())
                        .updateTime(submission.getUpdateTime())
                        .files(fileDataList)
                        .build();
                })
                .collect(Collectors.toList());

            return TaskData.builder()
                .id(task.getId())
                .caseId(task.getCaseId())
                .taskName(task.getTaskName())
                .taskCode(task.getTaskCode())
                .status(task.getStatus())
                .stage(task.getStage())
                .moduleId(task.getModuleId())
                .submissions(submissionDataList)
                .build();
        })
        .collect(Collectors.toList());

    return ResponseEntity.ok(ProcessDataResponse.builder()
        .tasks(taskDataList)
        .build());
}
```

### 方案C：分页优化（推荐⭐⭐⭐⭐）

#### 2.4 分阶段获取数据

**接口设计：**

```http
GET /api/v1/cases/{caseId}/process-data?stage={stage}&page={page}&size={size}
Authorization: Bearer {token}
```

**查询参数：**
- `stage`: 阶段编号（1-7），不传则返回所有阶段
- `page`: 页码，默认1
- `size`: 每页大小，默认20

**响应示例：**

```json
{
  "code": 200,
  "message": "success",
  "data": {
    "stage": 1,
    "page": 1,
    "size": 20,
    "total": 25,
    "totalPages": 2,
    "tasks": [
      {
        "id": 1,
        "caseId": 16,
        "taskName": "提交破产申请材料",
        "taskCode": "TASK_001_1",
        "status": "COMPLETED",
        "stage": 1,
        "moduleId": "1-1",
        "submissions": [...]
      }
    ]
  }
}
```

## 三、数据库优化

### 3.1 添加索引

```sql
-- 为批量查询添加索引
CREATE INDEX idx_case_task_case_id ON case_task(case_id);
CREATE INDEX idx_case_task_submission_case_task_id ON case_task_submission(case_task_id);
CREATE INDEX idx_case_task_submission_create_time ON case_task_submission(create_time DESC);
CREATE INDEX idx_submission_file_submission_id ON submission_file(submission_id);
CREATE INDEX idx_submission_file_sort_order ON submission_file(submission_id, sort_order);
```

### 3.2 使用JOIN查询优化

```java
// 使用JOIN一次性查询关联数据
@Query("""
    SELECT t FROM CaseTask t
    LEFT JOIN FETCH t.submissions s
    LEFT JOIN FETCH s.files f
    WHERE t.caseId = :caseId
    ORDER BY t.stage, t.moduleId
""")
List<CaseTask> findWithSubmissionsAndFiles(@Param("caseId") Long caseId);
```

## 四、缓存策略

### 4.1 Redis缓存

```java
@Service
public class CaseProcessDataCache {

    @Autowired
    private RedisTemplate<String, Object> redisTemplate;

    private static final String CACHE_PREFIX = "case:process:";
    private static final long CACHE_TTL = 5 * 60; // 5分钟

    public ProcessDataResponse getFromCache(Long caseId) {
        String key = CACHE_PREFIX + caseId;
        return (ProcessDataResponse) redisTemplate.opsForValue().get(key);
    }

    public void saveToCache(Long caseId, ProcessDataResponse data) {
        String key = CACHE_PREFIX + caseId;
        redisTemplate.opsForValue().set(key, data, CACHE_TTL, TimeUnit.MINUTES);
    }

    public void invalidateCache(Long caseId) {
        String key = CACHE_PREFIX + caseId;
        redisTemplate.delete(key);
    }
}
```

### 4.2 缓存失效策略

- **主动失效**：在数据更新时主动清除缓存
- **定时刷新**：后台定时任务刷新热点数据
- **版本控制**：为缓存数据添加版本号，避免脏数据

## 五、前端适配

### 5.1 使用聚合接口

```typescript
// 修改 loadAllStageData 函数
const loadAllStageData = async () => {
  loading.value = true;
  try {
    const startTime = Date.now();
    console.log('[性能优化] 开始加载所有阶段数据');

    // 使用新的聚合接口
    const response = await CaseProcessApi.getCaseProcessData(props.caseId);

    if (response.code === 200 && response.data) {
      console.log(`[性能优化] 获取案件流程数据完成，耗时: ${Date.now() - startTime}ms`);

      // 清空所有阶段的模块数据
      stages.forEach((stage) => {
        stage.modules.forEach((module) => {
          module.data = [];
          module.task = null;
        });
      });

      // 分配数据到对应的模块
      response.data.tasks.forEach((task) => {
        for (const stage of stages) {
          const module = stage.modules.find(
            (m) =>
              m.title.includes(task.taskName) ||
              task.taskName.includes(m.title),
          );

          if (module) {
            module.task = task;
            completedModules.value[module.id] = task.status === 'COMPLETED';

            // 处理提交记录
            const submissions = task.submissions || [];
            module.data = submissions.map((submission) => ({
              id: submission.id,
              title: submission.submissionTitle,
              content: submission.submissionContent,
              creator: submission.creatorName,
              date: submission.createTime
                ? new Date(submission.createTime)
                    .toISOString()
                    .split('T')[0]
                : '',
              files: submission.files || [],
              status: submission.status,
              submissionNumber: submission.submissionNumber,
              createTime: submission.createTime,
              updateTime: submission.updateTime,
              taskId: task.id,
            }));

            break;
          }
        }
      });
    }

    const totalTime = Date.now() - startTime;
    console.log(`[性能优化] 所有阶段数据加载完成，总耗时: ${totalTime}ms`);
  } catch (error) {
    console.error('[性能优化] 加载所有阶段数据失败:', error);
    ElMessage.error('加载数据失败');
  } finally {
    loading.value = false;
  }
};
```

### 5.2 使用批量接口

```typescript
// 修改 loadAllStageData 函数使用批量接口
const loadAllStageData = async () => {
  loading.value = true;
  try {
    const startTime = Date.now();
    console.log('[性能优化] 开始加载所有阶段数据');

    // 1. 获取所有任务数据
    const tasksResponse = await CaseTaskApi.getCaseTasks({
      caseId: Number(props.caseId),
      page: 1,
      size: 100,
    });

    if (tasksResponse.code === 200 && tasksResponse.data) {
      console.log(`[性能优化] 获取任务列表完成，耗时: ${Date.now() - startTime}ms`);

      // 清空所有阶段的模块数据
      stages.forEach((stage) => {
        stage.modules.forEach((module) => {
          module.data = [];
          module.task = null;
        });
      });

      // 2. 批量获取所有任务的提交记录
      const taskIds = tasksResponse.data.content.map(task => task.id);
      const submissionsResponse = await CaseTaskSubmissionApi.getLatestSubmissionsBatch({ caseTaskIds: taskIds });

      if (submissionsResponse.code === 200 && submissionsResponse.data) {
        console.log(`[性能优化] 批量获取提交记录完成，耗时: ${Date.now() - startTime}ms`);

        // 3. 批量获取所有提交的文件
        const submissionIds = Object.values(submissionsResponse.data)
          .flat()
          .map(submission => submission.id);
        const filesResponse = await CaseTaskSubmissionApi.getSubmissionFilesBatch({ submissionIds });

        if (filesResponse.code === 200 && filesResponse.data) {
          console.log(`[性能优化] 批量获取文件列表完成，耗时: ${Date.now() - startTime}ms`);

          // 4. 分配数据到对应的模块
          tasksResponse.data.content.forEach((task) => {
            for (const stage of stages) {
              const module = stage.modules.find(
                (m) =>
                  m.title.includes(task.taskName) ||
                  task.taskName.includes(m.title),
              );

              if (module) {
                module.task = task;
                completedModules.value[module.id] = task.status === 'COMPLETED';

                const taskSubmissions = submissionsResponse.data[task.id] || [];
                module.data = taskSubmissions.map((submission) => ({
                  id: submission.id,
                  title: submission.submissionTitle,
                  content: submission.submissionContent,
                  creator: submission.creatorName,
                  date: submission.createTime
                    ? new Date(submission.createTime)
                        .toISOString()
                        .split('T')[0]
                    : '',
                  files: filesResponse.data[submission.id] || [],
                  status: submission.status,
                  submissionNumber: submission.submissionNumber,
                  createTime: submission.createTime,
                  updateTime: submission.updateTime,
                  taskId: task.id,
                }));

                break;
              }
            }
          });
        }
      }
    }

    const totalTime = Date.now() - startTime;
    console.log(`[性能优化] 所有阶段数据加载完成，总耗时: ${totalTime}ms`);
  } catch (error) {
    console.error('[性能优化] 加载所有阶段数据失败:', error);
    ElMessage.error('加载数据失败');
  } finally {
    loading.value = false;
  }
};
```

## 六、性能对比

### 6.1 优化前后对比

| 指标 | 优化前 | 方案A（批量接口） | 方案B（聚合接口） |
|------|--------|------------------|------------------|
| 请求次数 | 421次 | 3次 | 1次 |
| 预估耗时 | 40-80秒 | 3-5秒 | 1-2秒 |
| 网络开销 | 高 | 中 | 低 |
| 服务器负载 | 高 | 中 | 低 |
| 实现复杂度 | - | 中 | 中高 |

### 6.2 推荐方案

**短期（快速见效）：**
- ✅ 方案A：批量获取接口
- 实现简单，效果显著
- 可减少 90% 的请求次数
- 预估耗时降低到 3-5秒

**中期（性能最优）：**
- ✅ 方案B：聚合接口
- 一次性获取所有数据
- 性能最优，用户体验最好
- 预估耗时降低到 1-2秒

**长期（架构优化）：**
- ✅ 方案A + 方案B + 缓存
- 结合多种优化手段
- 支持高并发场景
- 可扩展性强

## 七、实施计划

### 7.1 第一阶段（1-2天）

**目标**：实现批量获取接口

- [ ] 实现批量获取提交记录接口
- [ ] 实现批量获取文件接口
- [ ] 添加数据库索引
- [ ] 前端适配批量接口
- [ ] 性能测试

### 7.2 第二阶段（2-3天）

**目标**：实现聚合接口

- [ ] 实现案件流程数据聚合接口
- [ ] 优化数据库查询（使用JOIN）
- [ ] 添加Redis缓存
- [ ] 前端适配聚合接口
- [ ] 性能测试

### 7.3 第三阶段（1-2天）

**目标**：监控和优化

- [ ] 添加性能监控
- [ ] 压力测试
- [ ] 优化慢查询
- [ ] 文档完善

## 八、注意事项

### 8.1 数据量限制

- 单次批量查询建议不超过1000条记录
- 大数据量场景建议使用分页
- 考虑添加超时机制

### 8.2 安全性

- 验证用户权限
- 限制批量查询的数量
- 防止SQL注入
- 敏感数据加密

### 8.3 兼容性

- 保留原有接口，逐步迁移
- 提供版本控制
- 向后兼容

## 九、API文档

### 9.1 批量获取提交记录

```http
POST /api/v1/case-task-submissions/latest/batch
```

**请求参数：**

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| caseTaskIds | number[] | 是 | 任务ID列表，最多100个 |

**响应参数：**

| 参数 | 类型 | 说明 |
|------|------|------|
| code | number | 状态码，200表示成功 |
| message | string | 响应消息 |
| data | object | 提交记录映射，key为任务ID，value为提交记录列表 |

### 9.2 批量获取提交文件

```http
POST /api/v1/case-task-submissions/files/batch
```

**请求参数：**

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| submissionIds | number[] | 是 | 提交ID列表，最多500个 |

**响应参数：**

| 参数 | 类型 | 说明 |
|------|------|------|
| code | number | 状态码，200表示成功 |
| message | string | 响应消息 |
| data | object | 文件列表映射，key为提交ID，value为文件列表 |

### 9.3 获取案件流程数据

```http
GET /api/v1/cases/{caseId}/process-data
```

**路径参数：**

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| caseId | number | 是 | 案件ID |

**响应参数：**

| 参数 | 类型 | 说明 |
|------|------|------|
| code | number | 状态码，200表示成功 |
| message | string | 响应消息 |
| data | object | 案件流程数据 |
| data.tasks | array | 任务列表 |
| data.tasks[].id | number | 任务ID |
| data.tasks[].caseId | number | 案件ID |
| data.tasks[].taskName | string | 任务名称 |
| data.tasks[].taskCode | string | 任务编码 |
| data.tasks[].status | string | 任务状态 |
| data.tasks[].stage | number | 阶段编号 |
| data.tasks[].moduleId | string | 模块ID |
| data.tasks[].submissions | array | 提交记录列表 |
| data.tasks[].submissions[].id | number | 提交ID |
| data.tasks[].submissions[].caseTaskId | number | 任务ID |
| data.tasks[].submissions[].submissionTitle | string | 提交标题 |
| data.tasks[].submissions[].submissionContent | string | 提交内容 |
| data.tasks[].submissions[].submissionType | string | 提交类型 |
| data.tasks[].submissions[].status | string | 提交状态 |
| data.tasks[].submissions[].submissionNumber | number | 提交序号 |
| data.tasks[].submissions[].creatorName | string | 创建人姓名 |
| data.tasks[].submissions[].createTime | string | 创建时间 |
| data.tasks[].submissions[].updateTime | string | 更新时间 |
| data.tasks[].submissions[].files | array | 文件列表 |
| data.tasks[].submissions[].files[].id | number | 文件ID |
| data.tasks[].submissions[].files[].submissionId | number | 提交ID |
| data.tasks[].submissions[].files[].originalFileName | string | 原始文件名 |
| data.tasks[].submissions[].files[].filePath | string | 文件路径 |
| data.tasks[].submissions[].files[].fileSize | number | 文件大小（字节） |
| data.tasks[].submissions[].files[].mimeType | string | MIME类型 |
| data.tasks[].submissions[].files[].uploadTime | string | 上传时间 |
| data.tasks[].submissions[].files[].uploadUserName | string | 上传人姓名 |
| data.tasks[].submissions[].files[].sortOrder | number | 排序序号 |
| data.tasks[].submissions[].files[].previewUrl | string | 预览URL |

## 十、总结

通过实施以上优化方案，可以显著提升案件流程数据的加载性能：

1. **请求次数**：从421次降低到1-3次，减少99%以上
2. **加载时间**：从40-80秒降低到1-5秒，提升90%以上
3. **用户体验**：大幅改善，用户无需长时间等待
4. **服务器负载**：显著降低，支持更多并发用户

建议优先实施**方案A（批量接口）**，快速见效；然后逐步实施**方案B（聚合接口）**，达到最优性能。
